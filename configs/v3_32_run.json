{
    "save_mode": "1orbax",
    "save_optimizer_state": true,
    "embd_pdrop": 0.1,
    "resid_pdrop": 0.05,
    "intermediate_size": 11008,
    "transformation": "pjit", 
    "layers": 2,
    "d_model": 4096,
    "n_heads": 32,
    "n_vocab": 32000,
    "norm": "rmsnorm",
    "pe": "rotary",
    "pe_rotary_dims": 64,
    
    "seq": 2048,
    "cores_per_replica": 8,
    "per_replica_batch": 1,
    "gradient_accumulation_steps": 1,
    "seed": 42,
  
    "epoch_num": 3,
    "anneal_steps": 23863,
    "total_steps": 71589,
    "lr": 8e-6,
    "end_lr": 8e-7,
    "weight_decay": 0.001,
    "warmup_ratio": 0.02,
  
    "tpu_size": 32,
  
    "bucket": "llm_base_models",
    "model_dir": "easylm/linli_inese_llama",
  
    "train_set": "gs://jax_llm_data/work_dreamily_translation_general.train.tfrecords",
    "val_set": {
              "test": "gs://jax_llm_data/dreamily_translation_general.test.tfrecords"
    },
  
    "val_batches": 2000,
    "val_every": 3000,
    "ckpt_every": 3000,
    "keep_every": 3000,
  
    "name": "llama7b_finetune",
    "wandb_project": "Linli-chinese-llama-finetune"
  }