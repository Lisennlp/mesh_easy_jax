{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8069b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import jax\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import mlxu\n",
    "from google.cloud import storage\n",
    "from jax.experimental.pjit import pjit\n",
    "from jax.sharding import PartitionSpec as PS\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.jax_utils import prefetch_to_device\n",
    "from transformers import GenerationConfig, FlaxLogitsProcessorList\n",
    "\n",
    "sys.path.append('/home/lishengping/projects/mesh_easy_jax')\n",
    "\n",
    "from easylm.checkpoint import StreamingCheckpointer\n",
    "from easylm.llama_model import LLaMAConfig, LLaMAConfig2, FlaxLLaMAForCausalLM, LLaMATokenizer\n",
    "from easylm.jax_utils import (\n",
    "    JaxRNG, next_rng, match_partition_rules, tree_apply,\n",
    "    set_random_seed, get_float_dtype_by_name, make_shard_and_gather_fns,\n",
    "    with_sharding_constraint, FlaxTemperatureLogitsWarper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385bf94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_path: easylm/linli_chinese_llama/step_4000/streaming_train_state\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'llm_base_models'\n",
    "directory_path = 'easylm/linli_chinese_llama'\n",
    "# directory_path = 'llama7b_finetune_mesh_jax_flax'\n",
    "\n",
    "client = storage.Client()\n",
    "model_dirs = {}\n",
    "for blob in client.list_blobs(bucket_name, prefix=directory_path):\n",
    "    if 'step_' in blob.name:\n",
    "        step = re.findall('step_(\\d+)',blob.name)[0]\n",
    "        model_dirs[int(step)] = blob.name\n",
    "model_dirs = sorted(model_dirs.items(), key=lambda x: x[0])\n",
    "step, model_path = model_dirs[-1]\n",
    "print(f'model_path: {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d26f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS_DEF = {\n",
    "    'seed': 42,\n",
    "    'initialize_jax_distributed': False,\n",
    "    'mesh_dim': '1,-1,1',\n",
    "    'dtype': 'bf16',\n",
    "    'input_length': 1024,\n",
    "    'seq_length': 2048,\n",
    "    'top_k': 10,\n",
    "    'top_p': 0.85,\n",
    "    'do_sample': True,\n",
    "    'num_beams': 1,\n",
    "    'add_bos_token': False,\n",
    "    'load_llama_config': '',\n",
    "    'load_checkpoint': '',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db880723",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = '/home/lishengping/linli_llama_chinese0606/tokenizer.model'\n",
    "tokenizer = LLaMATokenizer(\n",
    "            vocab_file=vocab_file,\n",
    "            padding_side='left',\n",
    "            truncation_side='right',\n",
    "        )\n",
    "\n",
    "prefix_tokenizer = LLaMATokenizer(\n",
    "            vocab_file=vocab_file,\n",
    "            padding_side='right',\n",
    "            truncation_side='left',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "959ab573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do_init: False\n"
     ]
    }
   ],
   "source": [
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    llama_config = LLaMAConfig2.get_default_config()\n",
    "    llama_config.add_cross_attention = False\n",
    "    llama_config.is_encoder_decoder = False\n",
    "    llama_config.cache = True\n",
    "#     llama_config.num_hidden_layers = 2    \n",
    "    llama_config.gradient_checkpointing = ''  \n",
    "    llama_config.output_attentions = False\n",
    "    llama_config.output_hidden_states = False\n",
    "    llama_config.return_dict = True\n",
    "    hf_model = FlaxLLaMAForCausalLM(llama_config, input_shape=(1, 2048), seed=42, _do_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54637eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load weight time: 1534.1503233909607\n",
      "shard weight time: 0.059808969497680664\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    checkpoint_config = StreamingCheckpointer.get_default_config({'save_optimizer_state': True})\n",
    "    checkpointer = StreamingCheckpointer(checkpoint_config, 'output')\n",
    "    load_checkpoint = f'params::gs://{bucket_name}/{model_path}'\n",
    "    _, train_state = checkpointer.load_trainstate_checkpoint(load_checkpoint, disallow_trainstate=True)\n",
    "print(f'load weight time: {time.time() - start}')\n",
    "\n",
    "if train_state['params'].get('params', None) is not None:\n",
    "    params = train_state['params']['params']\n",
    "else:\n",
    "    params = train_state\n",
    "\n",
    "start = time.time()  \n",
    "model_ps = match_partition_rules(LLaMAConfig.get_partition_rules(), params)\n",
    "shard_fns, _ = make_shard_and_gather_fns(model_ps, get_float_dtype_by_name('bf16'))\n",
    "\n",
    "print(f'shard weight time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56e4997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(\n",
    "    pjit,\n",
    "    in_shardings=(model_ps, PS(), PS(), PS()),\n",
    "    out_shardings=(PS(), PS())\n",
    ")\n",
    "def forward_generate(params, rng, batch, temperature):\n",
    "    batch = with_sharding_constraint(batch, PS(('dp')))\n",
    "    rng_generator = JaxRNG(rng)\n",
    "    output = hf_model.generate(\n",
    "        batch['input_tokens'],\n",
    "        attention_mask=batch['attention_mask'],\n",
    "        params=params['params'],\n",
    "        prng_key=rng_generator(),\n",
    "        logits_processor=FlaxLogitsProcessorList(\n",
    "            [FlaxTemperatureLogitsWarper(temperature)]\n",
    "        ),\n",
    "        generation_config=GenerationConfig(\n",
    "            max_new_tokens=FLAGS_DEF['seq_length'] - FLAGS_DEF['input_length'],\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=FLAGS_DEF['do_sample'],\n",
    "            num_beams=FLAGS_DEF['num_beams'],\n",
    "            top_k=FLAGS_DEF['top_k'],\n",
    "            top_p=FLAGS_DEF['top_p'],\n",
    "        )\n",
    "    ).sequences[:, batch['input_tokens'].shape[1]:]\n",
    "    return output, rng_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988fd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_dim = '1, 8'\n",
    "mesh = LLaMAConfig2.get_jax_mesh(mesh_dim)\n",
    "set_random_seed(42)\n",
    "with mesh:\n",
    "    params = tree_apply(shard_fns, params)\n",
    "    sharded_rng = next_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a29de29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @staticmethod\n",
    "def generate(text, temperature):\n",
    "    global sharded_rng\n",
    "    inputs = prefix_tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=FLAGS_DEF['input_length'],\n",
    "        return_tensors='np',\n",
    "    )\n",
    "    input_tokens = inputs.input_ids\n",
    "    input_mask = inputs.attention_mask\n",
    "    if FLAGS_DEF['add_bos_token']:\n",
    "        input_tokens[:, 0] = tokenizer.bos_token_id\n",
    "        input_mask[:, 0] = 1\n",
    "    batch = dict(\n",
    "        input_tokens=input_tokens,\n",
    "        attention_mask=input_mask,\n",
    "    )\n",
    "    with mesh:\n",
    "        output, sharded_rng = forward_generate(\n",
    "            params, sharded_rng, batch, temperature\n",
    "        )\n",
    "        output = jax.device_get(output)\n",
    "    output_text = []\n",
    "    for text in list(tokenizer.batch_decode(output)):\n",
    "        if tokenizer.eos_token in text:\n",
    "            text = text.split(tokenizer.eos_token, maxsplit=1)[0]\n",
    "        output_text.append(text)\n",
    "\n",
    "    return output_text, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40cf46d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "文字：\n",
      "周杰伦，1979年1月18日出生于台湾台北市，台湾著名歌手、音乐制作人、演员、作家、商人。\n",
      "\n",
      "音乐方面，周杰伦是华语流行乐坛的代表性人物之一，曾获得过多项金曲奖、MTV音乐录影带大奖等奖项。他的音乐风格多样，包括流行、摇滚、电子、嘻哈等，并在音乐制作方面有着极高的造诣。他的歌曲在华语乐坛有着深远的影响力，被誉为“华语乐坛的顶级创作人”。\n",
      "\n",
      "除了音乐方面，周杰伦还涉足演艺界，曾出演过多部电影和电视剧，并获得过金马奖等奖项。他还是一位作家，出版了多部小说和散文集。\n",
      "\n",
      "除此之外，周杰伦还是一位成功的商人，他创立了自己的品牌Jaywalk，并在全球范围内拥有多家餐厅、酒吧和咖啡店。\n",
      "\n",
      "总之，周杰伦是一位多才多艺的艺人，他在音乐、演艺、商业等领域都有着极高的成就和影响力。\n"
     ]
    }
   ],
   "source": [
    "text = 'human:中国的首都在哪？\\nassistant：'\n",
    "# text = '新北市府南大門今天上午9點10分被人潑白漆，警方調查，一名男子持一桶白色油漆，步行到市府大門口潑漆後，立即騎機車逃逸，'\n",
    "# text = '周杰伦是谁'\n",
    "# text = 'Today, I want to'\n",
    "text = 'human:请用python实现冒泡排序算法\\n\\nassistant：'\n",
    "text = 'human:北京有哪些好玩的地方？\\n\\nassistant：'\n",
    "text = 'human:23 + 56 = ？\\n\\nassistant：'\n",
    "text = 'human:\\n写一篇300字的小说\\n\\nassistant:\\n'\n",
    "text = 'human:\\n不积跬步无以至千里，扩写\\n\\nassistant:\\n'\n",
    "text = 'Human:\\n美国总统是谁\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n中国主席是？\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n2023年中国主席是？\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n提取实体：我爱中国天安门\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n你能做什么\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n帮我写一份旅游青岛的7天计划\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n怎么追女生\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n211 + 1912 = ？\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\nx +y = 4\\n x - y =3,求x, y\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n用英文写一首歌\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n怎么做红烧肉\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n四大名著\\n\\nAssistant:\\n'\n",
    "text = 'Human:\\n周杰伦是谁，详细点介绍\\n\\nAssistant:\\n'\n",
    "\n",
    "r = generate(text, temperature=0.5)\n",
    "print(f'output:\\n{r[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7545508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f196f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
